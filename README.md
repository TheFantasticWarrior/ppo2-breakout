# PPO2-Breakout implementation
## needs help
Explained variance is always near 0

Model does learn but not as effective as OpenAI's PPO2 implementation, although code is as identical as I can make it

Originally tried to make [this](https://openai.com/research/reinforcement-learning-with-prediction-based-rewards) but failed and trying in an easier environment with simpler model and still failed, which explains the weird variable names

Did try to make the code less ugly but might made some bugs in process, although there are probably bugs I can't find
